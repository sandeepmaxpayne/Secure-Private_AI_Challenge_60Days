{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from keras import backend\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 10\n",
    "CHANNELS = 3\n",
    "IMAGE_SIZE = 500\n",
    "IMAGE_WIDTH = IMAGE_SIZE\n",
    "IMAGE_HEIGHT = IMAGE_SIZE\n",
    "IMAGENET_MEAN_RGB_VALUES = [123.68, 116.779, 103.939]\n",
    "CONTENT_WEIGHT = 0.02\n",
    "STYLE_WEIGHT = 4.5\n",
    "TOTAL_VARIATION_WEIGHT = 0.995\n",
    "TOTAL_VARIATION_LOSS_FACTOR = 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = \"input.png\"\n",
    "style_image_path = \"style.png\"\n",
    "output_image_path = \"output.png\"\n",
    "combined_image_path = \"combined.png\"\n",
    "\n",
    "\n",
    "chicken_image_path = \"C:/Users/Sandeep/Desktop/chicken.jpg\"\n",
    "\n",
    "sandeep_image_path = \"C:/Users/Sandeep/Desktop/sandeep.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Input visualization \n",
    "input_image = Image.open(chicken_image_path)\n",
    "input_image = input_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "input_image.save(input_image_path)\n",
    "input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image = Image.open(sandeep_image_path)\n",
    "style_image = style_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "style_image.save(style_image_path)\n",
    "style_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization and reshaping from RGB to BGR\n",
    "input_image_array = np.asarray(input_image, dtype=\"float32\")\n",
    "input_image_array = np.expand_dims(input_image_array, axis=0)\n",
    "input_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\n",
    "input_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\n",
    "input_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\n",
    "input_image_array = input_image_array[:, :, :, ::-1]\n",
    "\n",
    "style_image_array = np.asarray(style_image, dtype=\"float32\")\n",
    "style_image_array = np.expand_dims(style_image_array, axis=0)\n",
    "style_image_array[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\n",
    "style_image_array[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\n",
    "style_image_array[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\n",
    "style_image_array = style_image_array[:, :, :, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "input_image = backend.variable(input_image_array)\n",
    "style_image = backend.variable(style_image_array)\n",
    "combination_image = backend.placeholder((1, IMAGE_HEIGHT, IMAGE_SIZE, 3))\n",
    "\n",
    "input_tensor = backend.concatenate([input_image,style_image,combination_image], axis=0)\n",
    "model = VGG16(input_tensor=input_tensor, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(content, combination):\n",
    "    return backend.sum(backend.square(combination - content))\n",
    "\n",
    "layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "content_layer = \"block2_conv2\"\n",
    "layer_features = layers[content_layer]\n",
    "content_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "\n",
    "loss = backend.variable(0.)\n",
    "loss += CONTENT_WEIGHT * content_loss(content_image_features,\n",
    "                                      combination_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = backend.dot(features, backend.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_style_loss(style, combination):\n",
    "    style = gram_matrix(style)\n",
    "    combination = gram_matrix(combination)\n",
    "    size = IMAGE_HEIGHT * IMAGE_WIDTH\n",
    "    return backend.sum(backend.square(style - combination)) / (4. * (CHANNELS ** 2) * (size ** 2))\n",
    "\n",
    "style_layers = [\"block1_conv2\", \"block2_conv2\", \"block3_conv3\", \"block4_conv3\", \"block5_conv3\"]\n",
    "for layer_name in style_layers:\n",
    "    layer_features = layers[layer_name]\n",
    "    style_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    style_loss = compute_style_loss(style_features, combination_features)\n",
    "    loss += (STYLE_WEIGHT / len(style_layers)) * style_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    a = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, 1:, :IMAGE_WIDTH-1, :])\n",
    "    b = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, :IMAGE_HEIGHT-1, 1:, :])\n",
    "    return backend.sum(backend.pow(a + b, TOTAL_VARIATION_LOSS_FACTOR))\n",
    "\n",
    "loss += TOTAL_VARIATION_WEIGHT * total_variation_loss(combination_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0731 15:30:47.979465  4088 deprecation.py:323] From C:\\Users\\Sandeep\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "outputs = [loss]\n",
    "outputs += backend.gradients(loss, combination_image)\n",
    "\n",
    "def evaluate_loss_and_gradients(x):\n",
    "    x = x.reshape((1, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
    "    outs = backend.function([combination_image], outputs)([x])\n",
    "    loss = outs[0]\n",
    "    gradients = outs[1].flatten().astype(\"float64\")\n",
    "    return loss, gradients\n",
    "\n",
    "class Evaluator:\n",
    "\n",
    "    def loss(self, x):\n",
    "        loss, gradients = evaluate_loss_and_gradients(x)\n",
    "        self._gradients = gradients\n",
    "        return loss\n",
    "\n",
    "    def gradients(self, x):\n",
    "        return self._gradients\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(0, 255, (1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)) - 128.\n",
    "\n",
    "# for i in range(ITERATIONS):\n",
    "x, loss, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.gradients, maxfun=20)\n",
    "print(\"Iteration %d completed with loss %d\" % (i, loss))\n",
    "    \n",
    "x = x.reshape((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
    "x = x[:, :, ::-1]\n",
    "x[:, :, 0] += IMAGENET_MEAN_RGB_VALUES[2]\n",
    "x[:, :, 1] += IMAGENET_MEAN_RGB_VALUES[1]\n",
    "x[:, :, 2] += IMAGENET_MEAN_RGB_VALUES[0]\n",
    "x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "output_image = Image.fromarray(x)\n",
    "output_image.save(output_image_path)\n",
    "output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing combined results\n",
    "combined = Image.new(\"RGB\", (IMAGE_WIDTH*3, IMAGE_HEIGHT))\n",
    "x_offset = 0\n",
    "for image in map(Image.open, [input_image_path, style_image_path, output_image_path]):\n",
    "    combined.paste(image, (x_offset, 0))\n",
    "    x_offset += IMAGE_WIDTH\n",
    "combined.save(combined_image_path)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
