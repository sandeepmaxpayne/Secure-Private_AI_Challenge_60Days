{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#define transform to normalize the data\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),])\n",
    "\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2922, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Building the feed forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "#forward Pass\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3029, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Build  a  feedForward networl\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "#flattten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(1, requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    y=x*2\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4938, -0.5574],\n",
      "        [-1.5389, -0.4607]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x000002924ECF0F60>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2807, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7469, -0.2787],\n",
      "        [-0.7695, -0.2303]])\n",
      "tensor([[-0.7469, -0.2787],\n",
      "        [-0.7695, -0.2303]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Autograd\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-2.2799e-03, -2.2799e-03, -2.2799e-03,  ..., -2.2799e-03,\n",
      "         -2.2799e-03, -2.2799e-03],\n",
      "        [ 1.0971e-03,  1.0971e-03,  1.0971e-03,  ...,  1.0971e-03,\n",
      "          1.0971e-03,  1.0971e-03],\n",
      "        [ 5.0755e-04,  5.0755e-04,  5.0755e-04,  ...,  5.0755e-04,\n",
      "          5.0755e-04,  5.0755e-04],\n",
      "        ...,\n",
      "        [ 1.9905e-03,  1.9905e-03,  1.9905e-03,  ...,  1.9905e-03,\n",
      "          1.9905e-03,  1.9905e-03],\n",
      "        [-6.1376e-05, -6.1376e-05, -6.1376e-05,  ..., -6.1376e-05,\n",
      "         -6.1376e-05, -6.1376e-05],\n",
      "        [ 1.8657e-03,  1.8657e-03,  1.8657e-03,  ...,  1.8657e-03,\n",
      "          1.8657e-03,  1.8657e-03]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training network\n",
    "from torch import optim\n",
    "#SGD stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weights Parameter containing:\n",
      "tensor([[-0.0267,  0.0204, -0.0298,  ..., -0.0219, -0.0324,  0.0193],\n",
      "        [ 0.0217, -0.0292, -0.0146,  ..., -0.0143, -0.0188, -0.0005],\n",
      "        [ 0.0103, -0.0214,  0.0099,  ..., -0.0181,  0.0203,  0.0018],\n",
      "        ...,\n",
      "        [-0.0287,  0.0256, -0.0031,  ..., -0.0040, -0.0168, -0.0004],\n",
      "        [ 0.0207,  0.0122, -0.0290,  ..., -0.0269,  0.0056,  0.0138],\n",
      "        [-0.0180,  0.0051, -0.0218,  ...,  0.0181, -0.0311, -0.0206]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "print('initial weights', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial Weigths Parameter containing:\n",
      "tensor([[-0.0267,  0.0204, -0.0298,  ..., -0.0219, -0.0324,  0.0193],\n",
      "        [ 0.0217, -0.0292, -0.0146,  ..., -0.0143, -0.0188, -0.0005],\n",
      "        [ 0.0103, -0.0214,  0.0099,  ..., -0.0181,  0.0203,  0.0018],\n",
      "        ...,\n",
      "        [-0.0287,  0.0256, -0.0031,  ..., -0.0040, -0.0168, -0.0004],\n",
      "        [ 0.0207,  0.0122, -0.0290,  ..., -0.0269,  0.0056,  0.0138],\n",
      "        [-0.0180,  0.0051, -0.0218,  ...,  0.0181, -0.0311, -0.0206]],\n",
      "       requires_grad=True)\n",
      "Gradient tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print('initial Weigths', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader)) #trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)  ##pass this train value \n",
    "images.resize_(64, 784)\n",
    "optimizer.zero_grad()\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward # For finding gradients\n",
    "print(\"Gradient\", model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weigths Parameter containing:\n",
      "tensor([[-0.0267,  0.0204, -0.0298,  ..., -0.0219, -0.0324,  0.0193],\n",
      "        [ 0.0217, -0.0292, -0.0146,  ..., -0.0143, -0.0188, -0.0005],\n",
      "        [ 0.0103, -0.0214,  0.0099,  ..., -0.0181,  0.0203,  0.0018],\n",
      "        ...,\n",
      "        [-0.0287,  0.0256, -0.0031,  ..., -0.0040, -0.0168, -0.0004],\n",
      "        [ 0.0207,  0.0122, -0.0290,  ..., -0.0269,  0.0056,  0.0138],\n",
      "        [-0.0180,  0.0051, -0.0218,  ...,  0.0181, -0.0311, -0.0206]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step() # take an update step and few the new weights\n",
    "print(\"Updated weigths\", model[0].weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss1.881784416210931\n",
      "Training Loss0.8288638996544169\n",
      "Training Loss0.5136452020167797\n",
      "Training Loss0.4227963140619589\n",
      "Training Loss0.38135267033188075\n"
     ]
    }
   ],
   "source": [
    "###Training the real data\n",
    "##*Exercise: * Implement the training pass for our network. If you implemented it correctly, you should see the training loss drop with each epoch.\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1) #flatten into 784 long vectors\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training Loss{running_loss/len(trainloader)}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With the network train we can check out the prediction\n",
    "\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "\n",
    "# Turn off the torch to speed up its part\n",
    "\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "ps = torch.exp(logps)\n",
    "view_classify(img.view(1,28,28), ps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
